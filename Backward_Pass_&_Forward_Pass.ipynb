{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aim:\n",
    "Implement Forward pass and Backward pass \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame with Scaled Inputs and Rounded Outputs:\n",
      "           0         1    y1   y2\n",
      "0  -0.272679  0.977338  0.34  1.0\n",
      "1  -1.687344 -0.336021  0.00  0.0\n",
      "2  -2.615447 -0.516119  0.00  0.0\n",
      "3   1.236250  1.360107  1.00  0.0\n",
      "4   0.656438  1.283839  1.00  1.0\n",
      "..       ...       ...   ...  ...\n",
      "95  0.237781  0.945657  1.00  1.0\n",
      "96 -1.121926  0.201012  0.00  0.0\n",
      "97  0.356983 -1.088301  1.00  1.0\n",
      "98 -0.115028  1.281999  1.00  0.0\n",
      "99 -1.770890  1.542009  1.00  0.0\n",
      "\n",
      "[100 rows x 4 columns]\n",
      "Initial weights from input to hidden layer:\n",
      "[[0.39147262 0.84744151]\n",
      " [0.90857018 0.72925374]]\n",
      "Initial weights from hidden to output layer:\n",
      "[[0.65499744 0.47020314]\n",
      " [0.83160104 0.58374433]]\n",
      "\n",
      "Epoch 1/10\n",
      "Loss after epoch 1: 0.2345\n",
      "\n",
      "Epoch 2/10\n",
      "Loss after epoch 2: 0.2216\n",
      "\n",
      "Epoch 3/10\n",
      "Loss after epoch 3: 0.2128\n",
      "\n",
      "Epoch 4/10\n",
      "Loss after epoch 4: 0.2069\n",
      "\n",
      "Epoch 5/10\n",
      "Loss after epoch 5: 0.2031\n",
      "\n",
      "Epoch 6/10\n",
      "Loss after epoch 6: 0.2006\n",
      "\n",
      "Epoch 7/10\n",
      "Loss after epoch 7: 0.1989\n",
      "\n",
      "Epoch 8/10\n",
      "Loss after epoch 8: 0.1979\n",
      "\n",
      "Epoch 9/10\n",
      "Loss after epoch 9: 0.1973\n",
      "\n",
      "Epoch 10/10\n",
      "Loss after epoch 10: 0.1969\n",
      "\n",
      "Final Loss after Training: 0.2523\n",
      "Final weights from input to hidden layer:\n",
      "[[0.69107941 1.17575701]\n",
      " [1.15533692 1.10281622]]\n",
      "Final weights from hidden to output layer:\n",
      "[[0.48850096 0.01749686]\n",
      " [0.81380356 0.18389655]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('dataset_lab 4.csv')\n",
    "\n",
    "data = df.iloc[:, 1:3]  \n",
    "\n",
    "y1 = df['y1'].values \n",
    "y2 = df['y2'].values  \n",
    "\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "\n",
    "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "scaled_y1 = sigmoid(y1)\n",
    "scaled_y2 = sigmoid(y2)\n",
    "\n",
    "scaled_y1_rounded = np.round(scaled_y1, 2)\n",
    "scaled_y2_rounded = np.round(scaled_y2, 2)\n",
    "\n",
    "final_df = pd.concat([scaled_df, pd.DataFrame({'y1': scaled_y1_rounded, 'y2': scaled_y2_rounded})], axis=1)\n",
    "\n",
    "print(\"Final DataFrame with Scaled Inputs and Rounded Outputs:\")\n",
    "print(final_df)\n",
    "\n",
    "inputs = final_df.iloc[:, :2].values \n",
    "targets = final_df[['y1', 'y2']].values  \n",
    "\n",
    "class FeedforwardNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.weights_input_hidden = np.random.rand(2, 2) \n",
    "        self.weights_hidden_output = np.random.rand(2, 2)  \n",
    "        print(\"Initial weights from input to hidden layer:\")\n",
    "        print(self.weights_input_hidden)\n",
    "        print(\"Initial weights from hidden to output layer:\")\n",
    "        print(self.weights_hidden_output)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass\n",
    "        self.hidden_input = np.dot(x, self.weights_input_hidden) \n",
    "        self.hidden_output = self.sigmoid(self.hidden_input)       \n",
    "\n",
    "        self.output_input = np.dot(self.hidden_output, self.weights_hidden_output)  \n",
    "        self.output = self.sigmoid(self.output_input)  \n",
    "\n",
    "        return self.output\n",
    "\n",
    "    def compute_loss(self, output, target):\n",
    "        loss = np.mean((output - target) ** 2)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, x, target, learning_rate=0.1):\n",
    "        # Backward pass\n",
    "        output_error = self.output - target  \n",
    "        output_delta = output_error * (self.output * (1 - self.output))  \n",
    "\n",
    "        hidden_error = np.dot(output_delta, self.weights_hidden_output.T) \n",
    "        hidden_delta = hidden_error * (self.hidden_output * (1 - self.hidden_output))  \n",
    "\n",
    "        # Update weights\n",
    "        self.weights_hidden_output -= np.dot(self.hidden_output.reshape(-1, 1), output_delta.reshape(1, -1)) * learning_rate\n",
    "        self.weights_input_hidden -= np.dot(x.T, hidden_delta) * learning_rate\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nn = FeedforwardNeuralNetwork()\n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "        for i in range(inputs.shape[0]):  \n",
    "            input_sample = inputs[i:i+1]  \n",
    "            target_output = targets[i:i+1]  \n",
    "\n",
    "            # Forward pass\n",
    "            output = nn.forward(input_sample)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = nn.compute_loss(output, target_output)\n",
    "\n",
    "            # Backward pass and update weights\n",
    "            nn.backward(input_sample, target_output)\n",
    "\n",
    "        print(f\"Loss after epoch {epoch + 1}: {loss:.4f}\")\n",
    "\n",
    "    predicted_outputs = np.array([nn.forward(inputs[i:i+1]) for i in range(inputs.shape[0])])\n",
    "    final_loss = nn.compute_loss(predicted_outputs, targets)\n",
    "\n",
    "    print(f\"\\nFinal Loss after Training: {final_loss:.4f}\")\n",
    "\n",
    "\n",
    "    print(\"Final weights from input to hidden layer:\")\n",
    "    print(nn.weights_input_hidden)\n",
    "    print(\"Final weights from hidden to output layer:\")\n",
    "    print(nn.weights_hidden_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame with Scaled Inputs and Rounded Outputs:\n",
      "           0         1         2         3         4         5         6  \\\n",
      "0  -0.272679  0.977338 -0.249751 -1.446797  0.998452 -0.920760  0.892476   \n",
      "1  -1.687344 -0.336021 -0.544462 -0.280237  0.474904  0.402117  0.193557   \n",
      "2  -2.615447 -0.516119  1.428494  0.389190  0.418987 -0.881964 -0.000698   \n",
      "3   1.236250  1.360107 -0.499821  0.105530 -0.405342 -0.128606  1.260565   \n",
      "4   0.656438  1.283839 -0.898324 -0.766801 -0.287172  0.660993  1.584834   \n",
      "..       ...       ...       ...       ...       ...       ...       ...   \n",
      "95  0.237781  0.945657 -1.042495  0.855609 -0.048710 -0.530082  1.812690   \n",
      "96 -1.121926  0.201012 -0.692906  0.067794  1.798697 -0.734485 -0.383396   \n",
      "97  0.356983 -1.088301 -1.115302  0.245471 -0.300292  0.318088  1.261362   \n",
      "98 -0.115028  1.281999 -0.291238 -0.048360 -1.297339 -0.545284 -0.165956   \n",
      "99 -1.770890  1.542009 -0.166437  1.088341 -0.958306  0.904579 -1.513239   \n",
      "\n",
      "           7         8         9    y1   y2  \n",
      "0   1.654583  0.905667 -0.423874  0.34  1.0  \n",
      "1  -1.149595  0.233165  0.140665  0.00  0.0  \n",
      "2   0.020782 -2.726924 -0.191136  0.00  0.0  \n",
      "3  -0.948671 -1.397881 -1.469526  1.00  0.0  \n",
      "4   0.799523 -1.491014  1.464532  1.00  1.0  \n",
      "..       ...       ...       ...   ...  ...  \n",
      "95 -1.631865 -1.927773  2.187379  1.00  1.0  \n",
      "96 -0.842134 -1.164100  0.795546  0.00  0.0  \n",
      "97 -0.579355  0.712994  0.074054  1.00  1.0  \n",
      "98 -1.094896  0.993868 -0.426866  1.00  0.0  \n",
      "99 -0.289750 -0.259942  0.416353  1.00  0.0  \n",
      "\n",
      "[100 rows x 12 columns]\n",
      "Initial weights from input to hidden layer:\n",
      "[[0.6085732  0.4141088  0.23981872 0.66703553 0.4951699 ]\n",
      " [0.0873461  0.7895479  0.47945865 0.03638157 0.11021279]\n",
      " [0.40113914 0.70872503 0.12960361 0.53155258 0.49696803]\n",
      " [0.05351402 0.85425086 0.23947522 0.48299277 0.19486713]\n",
      " [0.17520081 0.66020582 0.57687926 0.24558421 0.01445273]\n",
      " [0.23168767 0.09771156 0.43216746 0.45021199 0.64902012]\n",
      " [0.76879519 0.48196323 0.43493166 0.88462191 0.28729704]\n",
      " [0.65994004 0.20641158 0.49751993 0.30555771 0.66989057]\n",
      " [0.26466553 0.32291926 0.64136087 0.88426676 0.12931869]\n",
      " [0.73270642 0.38674056 0.76033759 0.0151324  0.14134507]]\n",
      "Initial weights from hidden to output layer:\n",
      "[[0.31137192 0.38830861]\n",
      " [0.62733076 0.87372176]\n",
      " [0.64757123 0.04546906]\n",
      " [0.77779621 0.39065848]\n",
      " [0.05554233 0.746531  ]]\n",
      "Initial biases for hidden layer:\n",
      "[0.73451521 0.03258447 0.04169468 0.09378708 0.96052354]\n",
      "Initial biases for output layer:\n",
      "[0.94918886 0.90006227]\n",
      "\n",
      "Epoch 1/10\n",
      "MSE after epoch 1: 0.3174\n",
      "\n",
      "Epoch 2/10\n",
      "MSE after epoch 2: 0.2376\n",
      "\n",
      "Epoch 3/10\n",
      "MSE after epoch 3: 0.2079\n",
      "\n",
      "Epoch 4/10\n",
      "MSE after epoch 4: 0.1924\n",
      "\n",
      "Epoch 5/10\n",
      "MSE after epoch 5: 0.1790\n",
      "\n",
      "Epoch 6/10\n",
      "MSE after epoch 6: 0.1671\n",
      "\n",
      "Epoch 7/10\n",
      "MSE after epoch 7: 0.1566\n",
      "\n",
      "Epoch 8/10\n",
      "MSE after epoch 8: 0.1474\n",
      "\n",
      "Epoch 9/10\n",
      "MSE after epoch 9: 0.1395\n",
      "\n",
      "Epoch 10/10\n",
      "MSE after epoch 10: 0.1326\n",
      "\n",
      "Final Loss after Training: 0.2859\n",
      "Final weights from input to hidden layer:\n",
      "[[ 0.63622245  0.82056971  0.61985928  0.97757661  0.37646301]\n",
      " [ 0.09978087  0.92857207  0.79739262  0.44695617 -0.09087628]\n",
      " [ 0.46262726  0.88783625  0.08458545  0.61714152  0.62340368]\n",
      " [ 0.07558991  0.99435263  0.62109812  0.78831856  0.04470898]\n",
      " [ 0.23852614  0.72736608  0.39606798  0.33472291  0.17944931]\n",
      " [ 0.2291634   0.37536081  0.63221816  0.52833021  0.51665272]\n",
      " [ 0.78718176  0.77619354  0.26712543  0.8039753   0.44554931]\n",
      " [ 0.67339292  0.5436239   0.63728578  0.44981673  0.65429674]\n",
      " [ 0.33534814  0.6503535   0.58993449  0.88579307  0.24753596]\n",
      " [ 0.78021838  0.84864239  0.96479392  0.53335069  0.07440779]]\n",
      "Final weights from hidden to output layer:\n",
      "[[ 0.02955137  0.26987313]\n",
      " [ 1.18996983  1.51931965]\n",
      " [ 1.19644711  0.28172705]\n",
      " [ 0.9421233   0.88481913]\n",
      " [-0.4204901   0.12581475]]\n",
      "Final biases for hidden layer:\n",
      "[ 0.62637545 -0.33353621 -0.09026188 -0.19307905  0.89681139]\n",
      "Final biases for output layer:\n",
      "[-0.81049684 -1.35143366]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset_lab 4.csv', index_col=0)\n",
    "\n",
    "data = df.iloc[ :,0:10] \n",
    "\n",
    "y1 = df['y1'].values  \n",
    "y2 = df['y2'].values  \n",
    "\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "\n",
    "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "scaled_y1 = sigmoid(y1)\n",
    "scaled_y2 = sigmoid(y2)\n",
    "\n",
    "scaled_y1_rounded = np.round(scaled_y1, 2)\n",
    "scaled_y2_rounded = np.round(scaled_y2, 2)\n",
    "\n",
    "final_df = pd.concat([scaled_df, pd.DataFrame({'y1': scaled_y1_rounded, 'y2': scaled_y2_rounded})], axis=1)\n",
    "\n",
    "print(\"Final DataFrame with Scaled Inputs and Rounded Outputs:\")\n",
    "print(final_df)\n",
    "\n",
    "inputs = final_df.iloc[:, :10].values \n",
    "targets = final_df[['y1', 'y2']].values  \n",
    "\n",
    "class FeedforwardNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.weights_input_hidden = np.random.rand(10, 5) \n",
    "        self.weights_hidden_output = np.random.rand(5, 2)  \n",
    "        self.biases_hidden = np.random.rand(5)  \n",
    "        self.biases_output = np.random.rand(2)  \n",
    "        print(\"Initial weights from input to hidden layer:\")\n",
    "        print(self.weights_input_hidden)\n",
    "        print(\"Initial weights from hidden to output layer:\")\n",
    "        print(self.weights_hidden_output)\n",
    "        print(\"Initial biases for hidden layer:\")\n",
    "        print(self.biases_hidden)\n",
    "        print(\"Initial biases for output layer:\")\n",
    "        print(self.biases_output)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass\n",
    "        self.hidden_input = np.dot(x, self.weights_input_hidden) + self.biases_hidden  \n",
    "        self.hidden_output = self.sigmoid(self.hidden_input)  \n",
    "\n",
    "        self.output_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.biases_output  \n",
    "        self.output = self.sigmoid(self.output_input)  \n",
    "\n",
    "        return self.output\n",
    "\n",
    "    def compute_loss(self, output, target):\n",
    "        loss = np.mean((output - target) ** 2)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, x, target, learning_rate=0.1):\n",
    "        # Backward pass\n",
    "        output_error = self.output - target  \n",
    "        output_delta = output_error * (self.output * (1 - self.output))  \n",
    "\n",
    "        hidden_error = np.dot(output_delta, self.weights_hidden_output.T)  \n",
    "        hidden_delta = hidden_error * (self.hidden_output * (1 - self.hidden_output)) \n",
    "\n",
    "        # Update weights and biases\n",
    "        self.weights_hidden_output -= np.dot(self.hidden_output.reshape(-1, 1), output_delta.reshape(1, -1)) * learning_rate\n",
    "        self.weights_input_hidden -= np.dot(x.T, hidden_delta) * learning_rate\n",
    "        self.biases_output -= output_delta.flatten() * learning_rate  \n",
    "        self.biases_hidden -= hidden_delta.flatten() * learning_rate  \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nn = FeedforwardNeuralNetwork()\n",
    "\n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "        mse_sum = 0\n",
    "        for i in range(inputs.shape[0]):  \n",
    "            input_sample = inputs[i:i+1]  \n",
    "            target_output = targets[i:i+1]  \n",
    "\n",
    "            # Forward pass\n",
    "            output = nn.forward(input_sample)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = nn.compute_loss(output, target_output)\n",
    "            mse_sum += loss\n",
    "\n",
    "            # Backward pass \n",
    "            nn.backward(input_sample, target_output)\n",
    "\n",
    "        mse = mse_sum / inputs.shape[0]\n",
    "        print(f\"MSE after epoch {epoch + 1}: {mse:.4f}\")\n",
    "\n",
    "    predicted_outputs = np.array([nn.forward(inputs[i:i+1]) for i in range(inputs.shape[0])])\n",
    "    final_loss = nn.compute_loss(predicted_outputs, targets)\n",
    "\n",
    "    print(f\"\\nFinal Loss after Training: {final_loss:.4f}\")\n",
    "\n",
    "    print(\"Final weights from input to hidden layer:\")\n",
    "    print(nn.weights_input_hidden)\n",
    "    print(\"Final weights from hidden to output layer:\")\n",
    "    print(nn.weights_hidden_output)\n",
    "    print(\"Final biases for hidden layer:\")\n",
    "    print(nn.biases_hidden)\n",
    "    print(\"Final biases for output layer:\")\n",
    "    print(nn.biases_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
